{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SmartClaim: Exploratory Data Analysis\n",
        "\n",
        "This notebook explores the synthetic insurance claims dataset to understand:\n",
        "- Class distribution (fraud vs legitimate)\n",
        "- Feature distributions and correlations\n",
        "- Patterns that distinguish fraudulent claims\n",
        "\n",
        "**Goal**: Build intuition before modeling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style for better-looking plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "\n",
        "# Add parent directories to path\n",
        "sys.path.insert(0, str(Path.cwd().parent.parent))\n",
        "\n",
        "print(\"‚úì Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load the Data\n",
        "\n",
        "First, let's load the synthetic claims data and take a quick look.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the data\n",
        "from src.data.load_data import load_claims_data\n",
        "\n",
        "df = load_claims_data(\"../../data/processed/synthetic_claims.csv\")\n",
        "\n",
        "print(f\"\\nDataset shape: {df.shape}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic info\n",
        "print(\"Dataset Info:\")\n",
        "df.info()\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Summary Statistics:\")\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Class Balance\n",
        "\n",
        "How many fraudulent vs legitimate claims do we have? This is critical because imbalanced datasets require special handling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Class distribution\n",
        "fraud_counts = df['is_fraud'].value_counts()\n",
        "fraud_pcts = df['is_fraud'].value_counts(normalize=True)\n",
        "\n",
        "print(\"Class Distribution:\")\n",
        "print(f\"  Legitimate (0): {fraud_counts[0]:,} ({fraud_pcts[0]:.2%})\")\n",
        "print(f\"  Fraud (1):      {fraud_counts[1]:,} ({fraud_pcts[1]:.2%})\")\n",
        "print(f\"\\n  Imbalance ratio: {fraud_counts[0] / fraud_counts[1]:.2f}:1\")\n",
        "\n",
        "# Visualize\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Count plot\n",
        "axes[0].bar(['Legitimate', 'Fraud'], fraud_counts.values, color=['#2ecc71', '#e74c3c'])\n",
        "axes[0].set_ylabel('Count', fontsize=12)\n",
        "axes[0].set_title('Class Distribution (Counts)', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "for i, v in enumerate(fraud_counts.values):\n",
        "    axes[0].text(i, v + 50, f'{v:,}', ha='center', fontweight='bold')\n",
        "\n",
        "# Percentage plot\n",
        "axes[1].pie(fraud_counts.values, labels=['Legitimate', 'Fraud'], autopct='%1.1f%%',\n",
        "            colors=['#2ecc71', '#e74c3c'], startangle=90)\n",
        "axes[1].set_title('Class Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüí° This is an imbalanced dataset - we'll need to handle this in modeling!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Numeric Feature Distributions\n",
        "\n",
        "Let's see how numeric features differ between fraud and legitimate claims.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Numeric features\n",
        "numeric_features = ['age', 'vehicle_age', 'claim_amount', 'num_prior_claims', \n",
        "                    'policy_tenure_months', 'reported_delay_days']\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, feature in enumerate(numeric_features):\n",
        "    # Plot distributions for each class\n",
        "    df[df['is_fraud'] == 0][feature].hist(ax=axes[idx], bins=30, alpha=0.6, \n",
        "                                            label='Legitimate', color='#2ecc71')\n",
        "    df[df['is_fraud'] == 1][feature].hist(ax=axes[idx], bins=30, alpha=0.6, \n",
        "                                            label='Fraud', color='#e74c3c')\n",
        "    \n",
        "    axes[idx].set_xlabel(feature.replace('_', ' ').title(), fontsize=11)\n",
        "    axes[idx].set_ylabel('Frequency', fontsize=11)\n",
        "    axes[idx].legend()\n",
        "    axes[idx].grid(alpha=0.3)\n",
        "    \n",
        "    # Add mean lines\n",
        "    legit_mean = df[df['is_fraud'] == 0][feature].mean()\n",
        "    fraud_mean = df[df['is_fraud'] == 1][feature].mean()\n",
        "    axes[idx].axvline(legit_mean, color='#2ecc71', linestyle='--', linewidth=2, alpha=0.8)\n",
        "    axes[idx].axvline(fraud_mean, color='#e74c3c', linestyle='--', linewidth=2, alpha=0.8)\n",
        "\n",
        "plt.suptitle('Feature Distributions: Fraud vs Legitimate', fontsize=16, fontweight='bold', y=1.00)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüîç Key Observations:\")\n",
        "print(\"  - Fraudulent claims tend to have higher amounts\")\n",
        "print(\"  - Fraudsters are often younger\")\n",
        "print(\"  - Fraudulent claims involve older vehicles\")\n",
        "print(\"  - Fraudsters have more prior claims\")\n",
        "print(\"  - Fraudulent claims are reported with longer delays\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Correlation Analysis\n",
        "\n",
        "Which features are correlated with fraud? Which features are correlated with each other?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation heatmap (numeric features only)\n",
        "numeric_df = df[numeric_features + ['has_police_report', 'is_fraud']]\n",
        "correlation_matrix = numeric_df.corr()\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
        "            fmt='.2f', square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('Feature Correlation Heatmap', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüîç Correlations with Fraud (is_fraud):\")\n",
        "fraud_corr = correlation_matrix['is_fraud'].sort_values(ascending=False)\n",
        "for feature, corr in fraud_corr.items():\n",
        "    if feature != 'is_fraud':\n",
        "        print(f\"  {feature:30s}: {corr:+.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Categorical Feature Analysis\n",
        "\n",
        "How do fraud rates vary across different accident types and regions?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fraud rates by categorical features\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Fraud rate by accident type\n",
        "fraud_by_accident = df.groupby('accident_type')['is_fraud'].agg(['mean', 'count'])\n",
        "fraud_by_accident['mean'].plot(kind='bar', ax=axes[0], color='#e74c3c', alpha=0.7)\n",
        "axes[0].set_ylabel('Fraud Rate', fontsize=12)\n",
        "axes[0].set_xlabel('Accident Type', fontsize=12)\n",
        "axes[0].set_title('Fraud Rate by Accident Type', fontsize=14, fontweight='bold')\n",
        "axes[0].set_ylim(0, max(fraud_by_accident['mean']) * 1.2)\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "for i, (idx, row) in enumerate(fraud_by_accident.iterrows()):\n",
        "    axes[0].text(i, row['mean'] + 0.005, f\"{row['mean']:.1%}\\n(n={row['count']})\", \n",
        "                ha='center', fontsize=9)\n",
        "\n",
        "# Fraud rate by region\n",
        "fraud_by_region = df.groupby('region')['is_fraud'].agg(['mean', 'count'])\n",
        "fraud_by_region['mean'].plot(kind='bar', ax=axes[1], color='#3498db', alpha=0.7)\n",
        "axes[1].set_ylabel('Fraud Rate', fontsize=12)\n",
        "axes[1].set_xlabel('Region', fontsize=12)\n",
        "axes[1].set_title('Fraud Rate by Region', fontsize=14, fontweight='bold')\n",
        "axes[1].set_ylim(0, max(fraud_by_region['mean']) * 1.2)\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "for i, (idx, row) in enumerate(fraud_by_region.iterrows()):\n",
        "    axes[1].text(i, row['mean'] + 0.005, f\"{row['mean']:.1%}\\n(n={row['count']})\", \n",
        "                ha='center', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüîç Key Observations:\")\n",
        "print(f\"  - Highest fraud rate accident type: {fraud_by_accident['mean'].idxmax()} ({fraud_by_accident['mean'].max():.1%})\")\n",
        "print(f\"  - Lowest fraud rate accident type: {fraud_by_accident['mean'].idxmin()} ({fraud_by_accident['mean'].min():.1%})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Police Report Impact\n",
        "\n",
        "Does having a police report correlate with fraud likelihood?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Police report analysis\n",
        "police_fraud = df.groupby('has_police_report')['is_fraud'].agg(['mean', 'count'])\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(['No Police Report', 'Has Police Report'], \n",
        "               police_fraud['mean'].values, \n",
        "               color=['#e74c3c', '#2ecc71'], alpha=0.7, edgecolor='black', linewidth=2)\n",
        "plt.ylabel('Fraud Rate', fontsize=12)\n",
        "plt.title('Fraud Rate: With vs Without Police Report', fontsize=14, fontweight='bold')\n",
        "plt.ylim(0, max(police_fraud['mean']) * 1.2)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add value labels\n",
        "for i, (idx, row) in enumerate(police_fraud.iterrows()):\n",
        "    plt.text(i, row['mean'] + 0.01, f\"{row['mean']:.1%}\\n({row['count']:,} claims)\", \n",
        "            ha='center', fontsize=11, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüîç Key Insight:\")\n",
        "print(f\"  - Claims WITHOUT police reports have {police_fraud.loc[0, 'mean']:.1%} fraud rate\")\n",
        "print(f\"  - Claims WITH police reports have {police_fraud.loc[1, 'mean']:.1%} fraud rate\")\n",
        "print(f\"  - Police reports are a strong indicator of legitimacy!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Summary & Insights for Modeling\n",
        "\n",
        "Based on this EDA, here's what we learned:\n",
        "\n",
        "### Key Patterns\n",
        "- **Class Imbalance**: ~12% fraud rate ‚Üí need to handle in modeling (class weights, SMOTE, or appropriate metrics)\n",
        "- **Strong Predictors**: \n",
        "  - Police report presence (strongest signal)\n",
        "  - Claim amount (higher = more suspicious)\n",
        "  - Reported delay (longer = more suspicious)\n",
        "  - Number of prior claims (more = more suspicious)\n",
        "  \n",
        "### Modeling Strategy\n",
        "1. **Handle imbalance**: Use class_weight='balanced' or scale_pos_weight\n",
        "2. **Metrics**: Focus on F1, Precision, Recall, and PR-AUC (not just accuracy)\n",
        "3. **Features**: All features show some discriminative power\n",
        "4. **Baseline**: Start with Logistic Regression, then try XGBoost for non-linear patterns\n",
        "\n",
        "**Ready for modeling!** üöÄ\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
